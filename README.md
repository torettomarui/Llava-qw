# Llava-qw
A 8b multimodal large model based on Llava and qwen2.5-instruct.

This multimodal is trained on the datasets same as Llava, but use different vision model and language model. This multimodel use InternViT as vision model and QW-2.5-instruct-7b as language model.

## Performance
This multimodel achieved a score of 0.446 on the MMMU benchmark, surpassing the 0.35 score of Llava-13b.

Llava-qw-8b
![IMG_8371](https://github.com/user-attachments/assets/ac3fc893-3fae-4514-bea1-c34a82a0c078)

Llava-13b
![IMG_8371](https://github.com/user-attachments/assets/65079012-54ef-4b60-82a3-0ee04ab5f566)

## Demo
You can access this model by huggingface.
